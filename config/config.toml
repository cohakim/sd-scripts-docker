
[general_arguments]
pretrained_model_name_or_path="/training_data/pretrained_model.safetensors"
output_dir="/output"
output_name="mylora"
save_model_as="safetensors"
network_module="networks.lora"
persistent_data_loader_worker=true
mixed_precision="bf16"
xformers=true
train_batch_size=1
clip_skip=2
seed=42

[optimizer_arguments]
optimizer_type="AdamW8bit"
lr_scheduler="cosine_with_restarts"
lr_scheduler_num_cycles=4
lr_warmup_steps=0

[learning_arguments]
learning_rate=1e-4
network_dim=128
network_alpha=128
max_train_epochs=1
